{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotate Latin Inscriptions with Gemini API\n",
    "\n",
    "This notebook provides a complete workflow for:\n",
    "1. Downloading epigraphic data from EDH (Epigraphic Database Heidelberg)\n",
    "2. Annotating inscriptions using Gemini Flash 2.5 API\n",
    "3. Validating annotation quality\n",
    "4. Saving results and committing to git\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "1. **Google AI API Key**: Get one at https://aistudio.google.com/app/apikey\n",
    "2. **Installed packages**: Run the setup cell below\n",
    "\n",
    "## Cost Estimate\n",
    "\n",
    "- Gemini Flash 2.5: ~$0.20-0.50 USD per 1000 inscriptions\n",
    "- Processing time: ~20-40 minutes per 1000 inscriptions (with 1s delay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q google-generativeai pandas requests\n",
    "\n",
    "# Install latinepi if not already installed\n",
    "import os\n",
    "if not os.path.exists('latinepi'):\n",
    "    print(\"Installing latinepi package...\")\n",
    "    !pip install -e . -q\n",
    "else:\n",
    "    print(\"latinepi already available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Optional\n",
    "import pandas as pd\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "try:\n",
    "    import google.generativeai as genai\n",
    "    print(\"‚úÖ Google Generative AI imported successfully\")\n",
    "except ImportError:\n",
    "    print(\"‚ùå Please run the installation cell above\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# CONFIGURATION - Adjust these settings\n",
    "# ========================================\n",
    "\n",
    "# Google AI API Key\n",
    "GOOGLE_AI_API_KEY = os.environ.get(\"GOOGLE_AI_API_KEY\", \"\")\n",
    "\n",
    "if not GOOGLE_AI_API_KEY:\n",
    "    print(\"‚ö†Ô∏è  No API key found in environment.\")\n",
    "    print(\"   Option 1: Set environment variable: export GOOGLE_AI_API_KEY='your-key'\")\n",
    "    print(\"   Option 2: Enter it directly in the next cell\")\n",
    "else:\n",
    "    print(f\"‚úÖ API key loaded (first 10 chars): {GOOGLE_AI_API_KEY[:10]}...\")\n",
    "\n",
    "# Gemini model to use\n",
    "GEMINI_MODEL = \"gemini-2.0-flash-exp\"  # Fast and cost-effective\n",
    "# Alternative: \"gemini-1.5-pro\" for higher quality (more expensive)\n",
    "\n",
    "# Output paths\n",
    "OUTPUT_DIR = Path(\"assets\")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "ANNOTATIONS_FILE = OUTPUT_DIR / \"gemini_annotations.jsonl\"\n",
    "CHECKPOINT_FILE = OUTPUT_DIR / \"gemini_annotations.jsonl.tmp\"\n",
    "\n",
    "# Processing parameters\n",
    "SAVE_CHECKPOINT_EVERY = 50  # Save progress every N inscriptions\n",
    "API_DELAY = 1.0  # Seconds between API calls (rate limiting)\n",
    "MAX_RETRIES = 3  # Retry failed API calls\n",
    "\n",
    "print(\"\\nüìã Configuration loaded:\")\n",
    "print(f\"   Model: {GEMINI_MODEL}\")\n",
    "print(f\"   Output: {ANNOTATIONS_FILE}\")\n",
    "print(f\"   Checkpoint every: {SAVE_CHECKPOINT_EVERY} inscriptions\")\n",
    "print(f\"   API delay: {API_DELAY}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you need to set API key directly (not from environment):\n",
    "# GOOGLE_AI_API_KEY = \"paste-your-key-here\"\n",
    "# genai.configure(api_key=GOOGLE_AI_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Download Inscription Data from EDH\n",
    "\n",
    "We'll use the `latinepi` package to search and download inscriptions from the Epigraphic Database Heidelberg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDH Search Parameters\n",
    "# Adjust these to get different inscription sets\n",
    "\n",
    "SEARCH_PARAMS = {\n",
    "    \"year_from\": 1,      # 1 CE\n",
    "    \"year_to\": 100,      # 100 CE (1st century)\n",
    "    \"limit\": 2000,       # Number of inscriptions to download\n",
    "}\n",
    "\n",
    "DOWNLOAD_DIR = Path(\"edh_downloads/batch_\" + datetime.now().strftime(\"%Y%m%d_%H%M%S\"))\n",
    "\n",
    "print(f\"üîç Search parameters:\")\n",
    "for key, value in SEARCH_PARAMS.items():\n",
    "    print(f\"   {key}: {value}\")\n",
    "print(f\"\\nüìÇ Will download to: {DOWNLOAD_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download inscriptions from EDH using latinepi command-line tool\n",
    "import subprocess\n",
    "\n",
    "DOWNLOAD_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "cmd = [\n",
    "    \"latinepi\",\n",
    "    \"--search-edh\",\n",
    "    \"--search-year-from\", str(SEARCH_PARAMS[\"year_from\"]),\n",
    "    \"--search-year-to\", str(SEARCH_PARAMS[\"year_to\"]),\n",
    "    \"--search-limit\", str(SEARCH_PARAMS[\"limit\"]),\n",
    "    \"--download-dir\", str(DOWNLOAD_DIR),\n",
    "]\n",
    "\n",
    "print(f\"‚è≥ Downloading {SEARCH_PARAMS['limit']} inscriptions from EDH...\")\n",
    "print(f\"   Command: {' '.join(cmd)}\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "try:\n",
    "    result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)\n",
    "    print(result.stdout)\n",
    "    if result.stderr:\n",
    "        print(\"Errors/Warnings:\")\n",
    "        print(result.stderr)\n",
    "    \n",
    "    # Count downloaded files\n",
    "    json_files = list(DOWNLOAD_DIR.glob(\"*.json\"))\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"‚úÖ Downloaded {len(json_files)} inscription files\")\n",
    "    \n",
    "except subprocess.TimeoutExpired:\n",
    "    print(\"‚ö†Ô∏è  Download timed out after 5 minutes\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error during download: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load and Prepare Inscription Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_leiden_text(text):\n",
    "    \"\"\"\n",
    "    Clean Leiden convention markup from inscription text.\n",
    "    Converts diplomatic transcription to plain Latin text.\n",
    "    \"\"\"\n",
    "    if pd.isna(text) or text == \"\":\n",
    "        return \"\"\n",
    "    \n",
    "    text = str(text)\n",
    "    \n",
    "    # Remove lost text markers\n",
    "    text = re.sub(r\"\\[\\s*-+\\??\\s*\\]\", \"\", text)\n",
    "    text = re.sub(r\"-+\\]\", \"\", text)\n",
    "    text = re.sub(r\"\\[-+\", \"\", text)\n",
    "    \n",
    "    # Replace line breaks with spaces\n",
    "    text = text.replace(\"/\", \" \")\n",
    "    \n",
    "    # Remove Leiden markup\n",
    "    text = text.replace(\"(\", \"\").replace(\")\", \"\")  # Abbreviations\n",
    "    text = text.replace(\"[\", \"\").replace(\"]\", \"\")  # Restorations\n",
    "    text = text.replace(\"?\", \"\")  # Uncertain readings\n",
    "    \n",
    "    # Normalize whitespace\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "def load_inscriptions_from_json_dir(json_dir: Path) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Load and clean inscriptions from a directory of JSON files.\n",
    "    \n",
    "    Returns:\n",
    "        List of dicts with keys: id, text, transcription\n",
    "    \"\"\"\n",
    "    json_files = list(json_dir.glob(\"*.json\"))\n",
    "    \n",
    "    inscriptions = []\n",
    "    \n",
    "    for json_file in json_files:\n",
    "        try:\n",
    "            with open(json_file, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "            \n",
    "            # Get diplomatic text and transcription\n",
    "            raw_text = data.get(\"diplomatic_text\", \"\")\n",
    "            transcription = data.get(\"transcription\", \"\")\n",
    "            \n",
    "            # Clean the transcription\n",
    "            cleaned = clean_leiden_text(transcription)\n",
    "            \n",
    "            # Only include if we have text\n",
    "            if cleaned and len(cleaned.strip()) > 2:\n",
    "                inscriptions.append({\n",
    "                    \"id\": data.get(\"id\", json_file.stem),\n",
    "                    \"text\": raw_text,\n",
    "                    \"transcription\": cleaned\n",
    "                })\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è  Error loading {json_file.name}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return inscriptions\n",
    "\n",
    "\n",
    "# Load inscriptions\n",
    "print(f\"üìö Loading inscriptions from {DOWNLOAD_DIR}...\")\n",
    "inscriptions = load_inscriptions_from_json_dir(DOWNLOAD_DIR)\n",
    "\n",
    "print(f\"\\n‚úÖ Loaded {len(inscriptions)} inscriptions with valid text\")\n",
    "\n",
    "# Show sample\n",
    "if inscriptions:\n",
    "    print(\"\\nüìã Sample inscription:\")\n",
    "    sample = inscriptions[0]\n",
    "    print(f\"   ID: {sample['id']}\")\n",
    "    print(f\"   Text: {sample['transcription'][:80]}...\")\n",
    "    print(f\"   Length: {len(sample['transcription'])} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Load Annotation Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the annotation prompt\n",
    "PROMPT_FILE = Path(\"gemini_annotation_prompt.md\")\n",
    "\n",
    "if not PROMPT_FILE.exists():\n",
    "    print(f\"‚ùå Prompt file not found: {PROMPT_FILE}\")\n",
    "    print(\"   Make sure you're running this notebook from the repository root\")\n",
    "else:\n",
    "    with open(PROMPT_FILE, 'r', encoding='utf-8') as f:\n",
    "        ANNOTATION_PROMPT = f.read()\n",
    "    \n",
    "    print(f\"‚úÖ Loaded annotation prompt from {PROMPT_FILE}\")\n",
    "    print(f\"   Prompt length: {len(ANNOTATION_PROMPT)} characters\")\n",
    "    print(f\"   Estimated tokens: ~{len(ANNOTATION_PROMPT.split()) * 1.3:.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Initialize Gemini API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Gemini API\n",
    "if not GOOGLE_AI_API_KEY:\n",
    "    raise ValueError(\n",
    "        \"No API key set! Either:\\n\"\n",
    "        \"1. Set environment variable: export GOOGLE_AI_API_KEY='your-key'\\n\"\n",
    "        \"2. Or set it directly in the configuration cell above\"\n",
    "    )\n",
    "\n",
    "genai.configure(api_key=GOOGLE_AI_API_KEY)\n",
    "\n",
    "# Initialize the model\n",
    "model = genai.GenerativeModel(\n",
    "    model_name=GEMINI_MODEL,\n",
    "    generation_config={\n",
    "        \"temperature\": 0.1,  # Low temperature for deterministic output\n",
    "        \"top_p\": 0.95,\n",
    "        \"top_k\": 40,\n",
    "        \"max_output_tokens\": 2048,\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Gemini API configured\")\n",
    "print(f\"   Model: {GEMINI_MODEL}\")\n",
    "print(f\"   Temperature: 0.1 (deterministic)\")\n",
    "print(f\"\\nüß™ Testing API connection...\")\n",
    "\n",
    "try:\n",
    "    test_response = model.generate_content(\"Say 'API connection successful' in exactly those words.\")\n",
    "    print(f\"   Response: {test_response.text.strip()}\")\n",
    "    print(\"   ‚úÖ API is working!\")\n",
    "except Exception as e:\n",
    "    print(f\"   ‚ùå API test failed: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Annotation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_single_inscription(inscription: Dict, prompt: str, model) -> Optional[Dict]:\n",
    "    \"\"\"\n",
    "    Annotate a single inscription using Gemini API.\n",
    "    \n",
    "    Args:\n",
    "        inscription: Dict with keys: id, text, transcription\n",
    "        prompt: The annotation prompt (system instructions)\n",
    "        model: Gemini model instance\n",
    "    \n",
    "    Returns:\n",
    "        Dict with annotations added, or None if failed\n",
    "    \"\"\"\n",
    "    # Prepare input JSON\n",
    "    input_json = json.dumps({\n",
    "        \"id\": inscription.get(\"id\", \"\"),\n",
    "        \"text\": inscription.get(\"text\", \"\"),\n",
    "        \"transcription\": inscription.get(\"transcription\", \"\")\n",
    "    }, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    # Construct full prompt\n",
    "    full_prompt = f\"\"\"{prompt}\n",
    "\n",
    "---\n",
    "\n",
    "Please annotate the following inscription:\n",
    "\n",
    "{input_json}\n",
    "\n",
    "Return ONLY the JSON object with annotations added. No other text.\n",
    "\"\"\"\n",
    "    \n",
    "    # Try API call with retries\n",
    "    for attempt in range(MAX_RETRIES):\n",
    "        try:\n",
    "            response = model.generate_content(full_prompt)\n",
    "            response_text = response.text.strip()\n",
    "            \n",
    "            # Clean up response\n",
    "            if response_text.startswith(\"```json\"):\n",
    "                response_text = response_text[7:]\n",
    "            if response_text.startswith(\"```\"):\n",
    "                response_text = response_text[3:]\n",
    "            if response_text.endswith(\"```\"):\n",
    "                response_text = response_text[:-3]\n",
    "            response_text = response_text.strip()\n",
    "            \n",
    "            # Parse JSON\n",
    "            result = json.loads(response_text)\n",
    "            \n",
    "            # Validate structure\n",
    "            if \"annotations\" not in result:\n",
    "                print(f\"‚ö†Ô∏è  Missing 'annotations' field for {inscription.get('id')}\")\n",
    "                return None\n",
    "            \n",
    "            if not isinstance(result[\"annotations\"], list):\n",
    "                print(f\"‚ö†Ô∏è  Invalid annotations format for {inscription.get('id')}\")\n",
    "                return None\n",
    "            \n",
    "            return result\n",
    "            \n",
    "        except json.JSONDecodeError as e:\n",
    "            if attempt < MAX_RETRIES - 1:\n",
    "                time.sleep(2 ** attempt)  # Exponential backoff\n",
    "                continue\n",
    "            print(f\"‚ùå JSON parse error for {inscription.get('id')} after {MAX_RETRIES} attempts\")\n",
    "            return None\n",
    "            \n",
    "        except Exception as e:\n",
    "            if attempt < MAX_RETRIES - 1:\n",
    "                time.sleep(2 ** attempt)\n",
    "                continue\n",
    "            print(f\"‚ùå API error for {inscription.get('id')}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def save_checkpoint(results: List[Dict], checkpoint_file: Path):\n",
    "    \"\"\"Save intermediate results to checkpoint file.\"\"\"\n",
    "    with open(checkpoint_file, 'w', encoding='utf-8') as f:\n",
    "        for result in results:\n",
    "            f.write(json.dumps(result, ensure_ascii=False) + '\\n')\n",
    "\n",
    "\n",
    "def save_final(results: List[Dict], output_file: Path, checkpoint_file: Path):\n",
    "    \"\"\"Save final results and clean up checkpoint.\"\"\"\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        for result in results:\n",
    "            # Remove any error markers\n",
    "            clean_result = {k: v for k, v in result.items() if k != \"_error\"}\n",
    "            f.write(json.dumps(clean_result, ensure_ascii=False) + '\\n')\n",
    "    \n",
    "    # Clean up checkpoint\n",
    "    if checkpoint_file.exists():\n",
    "        checkpoint_file.unlink()\n",
    "\n",
    "print(\"‚úÖ Annotation functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Run Batch Annotation\n",
    "\n",
    "‚ö†Ô∏è **Important**: This cell will make API calls and may take 30-60 minutes for 2000 inscriptions.\n",
    "\n",
    "Progress is saved every 50 inscriptions, so you can interrupt and resume if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Limit number of inscriptions for testing\n",
    "TEST_LIMIT = None  # Set to e.g. 10 for testing, None for all\n",
    "\n",
    "if TEST_LIMIT:\n",
    "    inscriptions_to_process = inscriptions[:TEST_LIMIT]\n",
    "    print(f\"‚ö†Ô∏è  TEST MODE: Processing only {TEST_LIMIT} inscriptions\")\n",
    "else:\n",
    "    inscriptions_to_process = inscriptions\n",
    "    print(f\"üìù Processing all {len(inscriptions)} inscriptions\")\n",
    "\n",
    "# Check for existing checkpoint\n",
    "completed = []\n",
    "resume_from = 0\n",
    "\n",
    "if CHECKPOINT_FILE.exists():\n",
    "    print(f\"\\nüìÇ Found checkpoint file: {CHECKPOINT_FILE}\")\n",
    "    with open(CHECKPOINT_FILE, 'r', encoding='utf-8') as f:\n",
    "        completed = [json.loads(line) for line in f]\n",
    "    resume_from = len(completed)\n",
    "    print(f\"   Resuming from index {resume_from}\")\n",
    "\n",
    "# Statistics\n",
    "stats = {\n",
    "    'start_time': datetime.now(),\n",
    "    'total': len(inscriptions_to_process),\n",
    "    'successful': len(completed),\n",
    "    'failed': 0,\n",
    "    'total_entities': sum(len(r.get('annotations', [])) for r in completed)\n",
    "}\n",
    "\n",
    "print(f\"\\nüöÄ Starting annotation...\")\n",
    "print(f\"   Total: {stats['total']}\")\n",
    "print(f\"   Already completed: {len(completed)}\")\n",
    "print(f\"   Remaining: {stats['total'] - resume_from}\")\n",
    "print(f\"   Save checkpoint every: {SAVE_CHECKPOINT_EVERY}\")\n",
    "print(f\"   API delay: {API_DELAY}s\")\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "\n",
    "# Process inscriptions\n",
    "for i, inscription in enumerate(inscriptions_to_process[resume_from:], start=resume_from):\n",
    "    inscription_id = inscription.get('id', f'index_{i}')\n",
    "    \n",
    "    # Progress indicator\n",
    "    progress_pct = (i + 1) / stats['total'] * 100\n",
    "    print(f\"[{i+1}/{stats['total']} ({progress_pct:.1f}%)] {inscription_id}... \", end=\"\", flush=True)\n",
    "    \n",
    "    # Annotate\n",
    "    result = annotate_single_inscription(inscription, ANNOTATION_PROMPT, model)\n",
    "    \n",
    "    if result:\n",
    "        completed.append(result)\n",
    "        num_entities = len(result.get('annotations', []))\n",
    "        stats['successful'] += 1\n",
    "        stats['total_entities'] += num_entities\n",
    "        print(f\"‚úì ({num_entities} entities)\")\n",
    "    else:\n",
    "        # Save failed case with error marker\n",
    "        completed.append({\n",
    "            **inscription,\n",
    "            \"annotations\": [],\n",
    "            \"_error\": True\n",
    "        })\n",
    "        stats['failed'] += 1\n",
    "        print(\"‚úó (failed)\")\n",
    "    \n",
    "    # Save checkpoint\n",
    "    if (i + 1) % SAVE_CHECKPOINT_EVERY == 0:\n",
    "        save_checkpoint(completed, CHECKPOINT_FILE)\n",
    "        elapsed = (datetime.now() - stats['start_time']).total_seconds()\n",
    "        rate = (i + 1) / elapsed\n",
    "        remaining = (stats['total'] - i - 1) / rate if rate > 0 else 0\n",
    "        print(f\"   üíæ Checkpoint saved ({len(completed)} completed, ~{remaining/60:.1f} min remaining)\")\n",
    "    \n",
    "    # Rate limiting\n",
    "    if i < stats['total'] - 1:\n",
    "        time.sleep(API_DELAY)\n",
    "\n",
    "# Save final results\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üíæ Saving final results...\")\n",
    "save_final(completed, ANNOTATIONS_FILE, CHECKPOINT_FILE)\n",
    "\n",
    "# Final statistics\n",
    "elapsed = (datetime.now() - stats['start_time']).total_seconds()\n",
    "avg_entities = stats['total_entities'] / max(1, stats['successful'])\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ ANNOTATION COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Total inscriptions: {stats['total']}\")\n",
    "print(f\"Successful: {stats['successful']}\")\n",
    "print(f\"Failed: {stats['failed']}\")\n",
    "print(f\"Success rate: {stats['successful']/stats['total']*100:.1f}%\")\n",
    "print(f\"\\nTotal entities annotated: {stats['total_entities']}\")\n",
    "print(f\"Avg entities per inscription: {avg_entities:.1f}\")\n",
    "print(f\"\\nTime elapsed: {elapsed/60:.1f} minutes\")\n",
    "print(f\"Rate: {stats['total']/elapsed*60:.1f} inscriptions/minute\")\n",
    "print(f\"\\nOutput saved to: {ANNOTATIONS_FILE}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Validate Annotations\n",
    "\n",
    "Run quality checks on the annotated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick validation\n",
    "print(\"üîç Running validation checks...\\n\")\n",
    "\n",
    "# Load results\n",
    "with open(ANNOTATIONS_FILE, 'r', encoding='utf-8') as f:\n",
    "    results = [json.loads(line) for line in f]\n",
    "\n",
    "# Count entity types\n",
    "entity_counts = Counter()\n",
    "errors = []\n",
    "overlapping = []\n",
    "\n",
    "for record in results:\n",
    "    text = record.get('transcription', '')\n",
    "    annotations = record.get('annotations', [])\n",
    "    \n",
    "    if not annotations:\n",
    "        continue\n",
    "    \n",
    "    # Count entity types\n",
    "    for ann in annotations:\n",
    "        if len(ann) == 3:\n",
    "            start, end, label = ann\n",
    "            entity_counts[label] += 1\n",
    "            \n",
    "            # Check bounds\n",
    "            if start < 0 or end > len(text) or start >= end:\n",
    "                errors.append({\n",
    "                    'id': record.get('id'),\n",
    "                    'error': f'Invalid bounds [{start}:{end}] for text length {len(text)}'\n",
    "                })\n",
    "    \n",
    "    # Check for overlaps\n",
    "    sorted_anns = sorted(annotations, key=lambda x: x[0])\n",
    "    for i in range(len(sorted_anns) - 1):\n",
    "        if sorted_anns[i][1] > sorted_anns[i+1][0]:  # end[i] > start[i+1]\n",
    "            overlapping.append({\n",
    "                'id': record.get('id'),\n",
    "                'overlap': f'{sorted_anns[i]} overlaps with {sorted_anns[i+1]}'\n",
    "            })\n",
    "\n",
    "# Print results\n",
    "print(\"üìä Entity Type Distribution:\")\n",
    "print(f\"{'Entity Type':<30} {'Count':>8}\")\n",
    "print(\"-\" * 40)\n",
    "for label, count in entity_counts.most_common():\n",
    "    print(f\"{label:<30} {count:8d}\")\n",
    "\n",
    "print(f\"\\nüîç Quality Checks:\")\n",
    "print(f\"   Total records: {len(results)}\")\n",
    "print(f\"   Records with annotations: {sum(1 for r in results if r.get('annotations'))}\")\n",
    "print(f\"   Total entities: {sum(entity_counts.values())}\")\n",
    "\n",
    "if errors:\n",
    "    print(f\"\\n‚ùå Found {len(errors)} errors:\")\n",
    "    for err in errors[:5]:\n",
    "        print(f\"   {err['id']}: {err['error']}\")\n",
    "    if len(errors) > 5:\n",
    "        print(f\"   ... and {len(errors) - 5} more\")\n",
    "else:\n",
    "    print(f\"\\n‚úÖ No boundary errors found\")\n",
    "\n",
    "if overlapping:\n",
    "    print(f\"\\n‚ö†Ô∏è  Found {len(overlapping)} overlapping spans:\")\n",
    "    for ovr in overlapping[:5]:\n",
    "        print(f\"   {ovr['id']}: {ovr['overlap']}\")\n",
    "    if len(overlapping) > 5:\n",
    "        print(f\"   ... and {len(overlapping) - 5} more\")\n",
    "else:\n",
    "    print(f\"\\n‚úÖ No overlapping spans found\")\n",
    "\n",
    "# Overall quality\n",
    "error_rate = len(errors) / max(1, len(results))\n",
    "overlap_rate = len(overlapping) / max(1, len(results))\n",
    "\n",
    "if error_rate == 0 and overlap_rate == 0:\n",
    "    quality = \"üåü EXCELLENT\"\n",
    "elif error_rate < 0.01 and overlap_rate < 0.05:\n",
    "    quality = \"‚úÖ GOOD\"\n",
    "elif error_rate < 0.05 and overlap_rate < 0.10:\n",
    "    quality = \"‚ö†Ô∏è  FAIR\"\n",
    "else:\n",
    "    quality = \"‚ùå NEEDS REVIEW\"\n",
    "\n",
    "print(f\"\\nüéØ Overall Quality: {quality}\")\n",
    "print(f\"   Error rate: {error_rate:.2%}\")\n",
    "print(f\"   Overlap rate: {overlap_rate:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Show Sample Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a few sample annotations\n",
    "import random\n",
    "\n",
    "samples = [r for r in results if r.get('annotations')]\n",
    "if samples:\n",
    "    print(\"üìã Sample Annotated Inscriptions:\\n\")\n",
    "    \n",
    "    for i, record in enumerate(random.sample(samples, min(3, len(samples))), 1):\n",
    "        print(\"=\" * 70)\n",
    "        print(f\"Sample {i}\")\n",
    "        print(\"=\" * 70)\n",
    "        print(f\"ID: {record.get('id', 'N/A')}\")\n",
    "        print(f\"Text: {record['transcription']}\")\n",
    "        print(f\"\\nEntities ({len(record['annotations'])}):\")\n",
    "        \n",
    "        for start, end, label in record['annotations'][:15]:  # Max 15 entities\n",
    "            entity_text = record['transcription'][start:end]\n",
    "            print(f\"  [{start:3d}:{end:3d}] {label:25s} = '{entity_text}'\")\n",
    "        \n",
    "        if len(record['annotations']) > 15:\n",
    "            print(f\"  ... and {len(record['annotations']) - 15} more\")\n",
    "        print()\n",
    "else:\n",
    "    print(\"No annotated samples to display\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Commit and Push Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from datetime import datetime\n",
    "\n",
    "# Generate commit message\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n",
    "commit_message = f\"\"\"Add Gemini-annotated inscriptions ({timestamp})\n",
    "\n",
    "Annotated {stats['successful']} inscriptions using {GEMINI_MODEL}\n",
    "- Total entities: {stats['total_entities']}\n",
    "- Avg entities per inscription: {avg_entities:.1f}\n",
    "- Success rate: {stats['successful']/stats['total']*100:.1f}%\n",
    "- Search params: {SEARCH_PARAMS['year_from']}-{SEARCH_PARAMS['year_to']} CE\n",
    "\n",
    "Files:\n",
    "- {ANNOTATIONS_FILE}\n",
    "- {DOWNLOAD_DIR}/ (raw EDH data)\n",
    "\"\"\"\n",
    "\n",
    "print(\"üìù Commit message:\")\n",
    "print(\"=\" * 70)\n",
    "print(commit_message)\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "\n",
    "# Ask for confirmation\n",
    "confirm = input(\"Commit and push these files? (yes/no): \").strip().lower()\n",
    "\n",
    "if confirm == 'yes':\n",
    "    try:\n",
    "        # Check git status\n",
    "        print(\"\\nüìä Git status:\")\n",
    "        result = subprocess.run(['git', 'status', '--short'], capture_output=True, text=True)\n",
    "        print(result.stdout)\n",
    "        \n",
    "        # Add files\n",
    "        print(\"\\nüì¶ Adding files to git...\")\n",
    "        subprocess.run(['git', 'add', str(ANNOTATIONS_FILE)], check=True)\n",
    "        subprocess.run(['git', 'add', str(DOWNLOAD_DIR)], check=True)\n",
    "        print(\"   ‚úÖ Files staged\")\n",
    "        \n",
    "        # Commit\n",
    "        print(\"\\nüíæ Creating commit...\")\n",
    "        subprocess.run(['git', 'commit', '-m', commit_message], check=True)\n",
    "        print(\"   ‚úÖ Commit created\")\n",
    "        \n",
    "        # Get current branch\n",
    "        branch_result = subprocess.run(\n",
    "            ['git', 'rev-parse', '--abbrev-ref', 'HEAD'],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            check=True\n",
    "        )\n",
    "        current_branch = branch_result.stdout.strip()\n",
    "        \n",
    "        # Push\n",
    "        print(f\"\\nüöÄ Pushing to origin/{current_branch}...\")\n",
    "        subprocess.run(['git', 'push', 'origin', current_branch], check=True)\n",
    "        print(\"   ‚úÖ Pushed successfully\")\n",
    "        \n",
    "        print(\"\\n‚úÖ All done!\")\n",
    "        \n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"\\n‚ùå Git operation failed: {e}\")\n",
    "        print(\"   You may need to commit and push manually\")\n",
    "        \n",
    "else:\n",
    "    print(\"\\n‚ÑπÔ∏è  Skipping git operations\")\n",
    "    print(f\"   To commit later, run:\")\n",
    "    print(f\"   git add {ANNOTATIONS_FILE} {DOWNLOAD_DIR}\")\n",
    "    print(f\"   git commit -m 'Add Gemini annotations'\")\n",
    "    print(f\"   git push\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Summary and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"üéâ WORKFLOW COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nüìä Results:\")\n",
    "print(f\"   Inscriptions downloaded: {len(json_files)}\")\n",
    "print(f\"   Inscriptions annotated: {stats['successful']}\")\n",
    "print(f\"   Total entities: {stats['total_entities']}\")\n",
    "print(f\"   Output file: {ANNOTATIONS_FILE}\")\n",
    "\n",
    "print(f\"\\nüî¨ Next Steps:\")\n",
    "print(f\"\\n1. Review annotation quality:\")\n",
    "print(f\"   python validate_annotations.py {ANNOTATIONS_FILE}\")\n",
    "\n",
    "print(f\"\\n2. Use in your training notebook:\")\n",
    "print(f\"   INPUT_FILE = '{ANNOTATIONS_FILE}'\")\n",
    "print(f\"   partition_data(INPUT_FILE, CLEAN_OUTPUT_FILE, FIX_OUTPUT_FILE)\")\n",
    "\n",
    "print(f\"\\n3. Compare with synthetic data:\")\n",
    "print(f\"   - Train model A: synthetic data only (463 examples)\")\n",
    "print(f\"   - Train model B: real data only ({stats['successful']} examples)\")\n",
    "print(f\"   - Train model C: combined\")\n",
    "print(f\"   - Evaluate all three on held-out real inscriptions\")\n",
    "\n",
    "print(f\"\\n4. If quality is good, annotate more:\")\n",
    "print(f\"   - Adjust SEARCH_PARAMS in cell 3\")\n",
    "print(f\"   - Download different time periods/regions\")\n",
    "print(f\"   - Aim for 5000+ total inscriptions\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
